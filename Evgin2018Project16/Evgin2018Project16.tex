\documentclass[12pt,twoside]{article}
\usepackage{jmlda}
\usepackage{cite}
\title
    [Оценка оптимального объема выборки для исследований в медицине]
    {Оценка оптимального объема выборки для исследований в медицине}
\author
    {Евгин~А.\,А.$^1$} % основной список авторов, выводимый в оглавление
\thanks
    {Научный руководитель:  Стрижов~В.\,В.
   Задачу поставил:  Катруца~А.\,М.
    Консультант:  T. Гадаев}
\email
    {aleasims@gmail.com}
\organization
     {$^1$Московский физико-технический институт}

\abstract
    {Задача посвящена нахождению оценки оптимальных размеров выборки, необходимых для медицинских иссоедований. Требуется спрогнозировать оптимальные объемы выборки в условиях ограниченного числа измерений. В качетсве алгоритма использутся серия эмпирических алгоритмов оценки объема выборки.

\bigskip
\textbf{Ключевые слова}: \emph {объем выборки}.}

\begin{document}
\maketitle

\section{Введение}
\paragraph{Цель исследования:}
Целью работы является создание и теоретическое обоснование методов оценки объема многофакторных выборок, учитывающих вид модели классификации и более точных по сравнению с известными методами; создание методов классификации малых выборок.
\paragraph{Предмет исследования:}
Оценить минимальный объём выборки — количество производимых измерений некоторого параметра или набора параметров, необходимый для выполнения некоторых ранее сформулированных условий.
\paragraph{Исследуемая проблема:}
Исследование направлено на решение проблемы выбора моделей при классификации выборок малой мощности. По заданной выборке, включающей многокритериальное описание объектов и метки класса объектов, требуется получить оценку структурных параметров, получить асимптотическую оценку необходимого объема выборки и указать предпочтительный подход к решению задачи классификации. Для классификации объекта требуется получить оценку параметров выбранной модели и выполнить анализ ошибок классификации.
\paragraph{Решаемая в данной работе задача:}
В данной работе основное внимание уделяется байесовским методам оценки объёма выборки. Оценка объёма выборки в байесовской постановке включает оценку апостериорного распределения $\mathsf{p}(D|w)$ параметров модели. При отсутствии наблюдаемых данных, апостериорное распределение$$ p(w,D) = \frac{p(D|w)p(w)}{p(D)}$$ совпадает с априорным $\mathsf{p}(w)$, как в классических методах оценки объёма выборки. Разница между вторым и третьим случаями заключается только в способе оценки распределения $\mathsf{p}(w|D)$ — на основе сэмплированных, либо реально наблюдаемых данных.

\paragraph{Предлагаемое решение:}
Статистические методы позволяют оценить объем выборки, исходя из предположений о распределении данных и информации о соответствии наблюдаемых величин предположениям нулевой гипотезы. В случае, если объем исследуемой выборки достаточен или избыточен, возможно применение методов, основанных на наблюдении за изменением некоторой характеристики процедуры построения модели при увеличении объема выборки. В частности, наблюдая за отношением качества прогнозирования на контрольной выборке и обучающей выборке, определим достаточный объем выборки как соответствующий началу переобучения. Таким же образом производится оценка объема выборки в рамках предлагаемого метода: предлагается считать объем выборки достаточным, если расстояние между распределениями, оцененными на подвыборках данного объема, достаточно мало. Такой подход не требует дополнительного обобщения на случай многих переменных. Кроме того, оценку можно производить как при наличии предположений о распределении данных, так и в их отсутствие.
\paragraph{Анализ сильных и слабых сторон предлагаемого решения:}
Недостатком данного подхода является то что количественные оценки возможно получить лишь в случае, когда объем выборки избыточен. В противном случае метод позволяет лишь определить, является ли текущий объем выборки достаточным

\subsection{Постановка задачи}
\paragraph{Постановка задачи классификации:}
Рассмотрим выборку вида $D_m =\{(\mathbf{x}_i, y_i)\}_{i = 1}^{m}$, где $\mathbf{x}_i\in\mathbb{R}^n$~--- описание $i$-го элемента выборки, а $y_i\in \mathcal{Y}$~--- его метка класса. Введем обозначение $D_m = (X,\mathbf{y})$, где $\mathbf{y} =
[y_1,\dots,y_m]^{R}$, $\X = [\mathbf{x}^{R}_1,\dots,\mathbf{x}^{R}_m]^{R}$~--- матрица плана.

В задаче классификации необходимо подстроить отображение наблюдаемых данных $\x \in \mathbb{R}^m$ на множество меток класса $\mathcal{Y}$. Будем называть функцию $a: \mathbb{R}^{m} \rightarrow \mathcal{Y}$ \textit{классификатором}.  Будем использовать подход максимизации правдоподобия данных.

\paragraph{Постановка задачи определения оптимального объёма выборки:}
При заведомо недостаточном количестве $m$ объектов выборки $D$ с распределением $\mathsf{P}(\vec{x},y)$ для обучения устойчивой логистической регрессии, требуется найти такое количество $m^*$ объектов выборки, которое будет достаточным.
\subsection{Вычислительный эксперимент}
\paragraph{Данные:}
Проведем эксперимент на вручную сгенерированых данных с нормальным распределением так, чтобы на них можно было протестировать работу алгоритмов классификации.
Размер синтетических данных соответсвует размеру исходных данных. Проведя эксперимент, было выяснено, что рассматриваемые выше глобальные параметры в модели на реальных данных стабилизируются быстрее, а именно при размерах выборки около 65 объектов. 
\subsection{Вывод}
Наибольшую ценность из вышеперичисленных параметров составила след матрицы ковариации. Данный компонет выходит на плато при размерах выборок более 80 объектов.

\bibliographystyle{plain}
\bibliography{Evgin2018Project16}
\nocite{*}
\end{document}
